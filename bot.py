import os
import logging
import openai
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import CommandStart
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç OPENAI_API_KEY. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Railway.")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
KNOWLEDGE_FILE = "knowledge.txt"

# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
def split_text_into_chunks(text: str, chunk_size: int = 500, overlap: int = 100):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.
    """
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
    chunks = text_splitter.split_text(text)
    return [Document(page_content=chunk) for chunk in chunks]

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ FAISS-–∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –ª–µ—Ç—É
if os.path.exists(KNOWLEDGE_FILE):
    with open(KNOWLEDGE_FILE, "r", encoding="utf-8") as f:
        knowledge_text = f.read()
    print(f"üîç –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –†–∞–∑–º–µ—Ä: {len(knowledge_text)} —Å–∏–º–≤–æ–ª–æ–≤.")

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –∏ —Å–æ–∑–¥–∞–µ–º FAISS
    docs = split_text_into_chunks(knowledge_text, chunk_size=500, overlap=100)
    if docs:
        vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
        print("‚úÖ FAISS-–∏–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –≤ –ø–∞–º—è—Ç–∏!")
    else:
        print("‚ùå –û—à–∏–±–∫–∞: –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Ä–∞–∑–±–∏—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏!")
        vector_store = None
else:
    print("‚ùå –§–∞–π–ª knowledge.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    vector_store = None

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(CommandStart())
async def start_handler(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—É –¢–∞–º–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–æ—é–∑–∞. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã!")

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def process_message(message: Message):
    user_input = message.text
    response = ask_ai(user_input)
    await message.answer(response)

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ FAISS –∏ OpenAI
def ask_ai(query: str) -> str:
    global vector_store
    context = ""

    if vector_store:
        docs = vector_store.similarity_search(query, k=2)  # –ò—â–µ–º 2 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–∞
        if docs:
            context = "\n".join([doc.page_content for doc in docs])
            print(f"üîç –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context}")  # –õ–æ–≥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã FAISS

    if not context:
        # –í–µ–∂–ª–∏–≤—ã–π –æ—Ç–∫–∞–∑
        return (
            "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —è –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—É –¢–∞–º–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–æ—é–∑–∞ "
            "–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω–æ–≥–æ –ø–æ–¥–≤–∏–∂–Ω–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞. "
            "–í–∞–º —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º –∏–ª–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )

    prompt = f"""
–¢—ã ‚Äì –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—É –¢–∞–º–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–æ—é–∑–∞ "–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò –ñ–ï–õ–ï–ó–ù–û–î–û–†–û–ñ–ù–û–ì–û –ü–û–î–í–ò–ñ–ù–û–ì–û –°–û–°–¢–ê–í–ê".
–¢—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—á–∞—Ç—å **–¢–û–õ–¨–ö–û –ü–û –ë–ê–ó–ï –ó–ù–ê–ù–ò–ô**.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –±–∞–∑–µ, **–≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è**.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã:
{context}

–í–æ–ø—Ä–æ—Å: {query}
"""

    client = openai.Client(api_key=OPENAI_API_KEY)
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[{"role": "system", "content": "–¢—ã ‚Äì —ç–∫—Å–ø–µ—Ä—Ç, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç."},
                      {"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {e}"

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
