import os
import logging
import openai
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import CommandStart
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç OPENAI_API_KEY. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Railway.")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
KNOWLEDGE_FILE = "knowledge.txt"
INSTRUCTION_FILE = "instruction.txt"

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
if os.path.exists(INSTRUCTION_FILE):
    with open(INSTRUCTION_FILE, "r", encoding="utf-8") as f:
        system_instruction = f.read().strip()
    print("‚úÖ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
else:
    system_instruction = "–¢—ã ‚Äì —ç–∫—Å–ø–µ—Ä—Ç, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç."
    print("‚ö† –§–∞–π–ª instruction.txt –Ω–µ –Ω–∞–π–¥–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.")

# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
def split_text_into_chunks(text: str, chunk_size: int = 500, overlap: int = 100):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
    chunks = text_splitter.split_text(text)
    return [Document(page_content=chunk) for chunk in chunks]

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ FAISS-–∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –ª–µ—Ç—É
if os.path.exists(KNOWLEDGE_FILE):
    with open(KNOWLEDGE_FILE, "r", encoding="utf-8") as f:
        knowledge_text = f.read()
    print(f"üîç –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –†–∞–∑–º–µ—Ä: {len(knowledge_text)} —Å–∏–º–≤–æ–ª–æ–≤.")

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –∏ —Å–æ–∑–¥–∞–µ–º FAISS
    docs = split_text_into_chunks(knowledge_text, chunk_size=500, overlap=100)
    if docs:
        vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
        print("‚úÖ FAISS-–∏–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –≤ –ø–∞–º—è—Ç–∏!")
    else:
        print("‚ùå –û—à–∏–±–∫–∞: –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Ä–∞–∑–±–∏—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏!")
        vector_store = None
else:
    print("‚ùå –§–∞–π–ª knowledge.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    vector_store = None

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(CommandStart())
async def start_handler(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å!")

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def process_message(message: Message):
    user_input = message.text
    response = ask_ai(user_input)
    await message.answer(response)

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ FAISS –∏ OpenAI
def ask_ai(query: str) -> str:
    global vector_store
    context = ""

    if vector_store:
        docs = vector_store.similarity_search(query, k=2)
        if docs:
            context = "\n".join([doc.page_content for doc in docs])
            print(f"üîç –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context}")

    if not context:
        return (
    "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ —è –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é —Ç–æ–ª—å–∫–æ –ø–æ –¢–ï–•–ù–ò–ß–ï–°–ö–æ–º—É –†–ï–ì–õ–ê–ú–ï–ù–¢—É –¢–ê–ú–û–ñ–ï–ù–ù–û–ì–û –°–û–Æ–ó–ê "
    "'–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò –ñ–ï–õ–ï–ó–ù–û–î–û–†–û–ñ–ù–û–ì–û –ü–û–î–í–ò–ñ–ù–û–ì–û –°–û–°–¢–ê–í–ê'. "
    "–í–∞–º —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º –∏–ª–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
)

    prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {query}"

    client = openai.Client(api_key=OPENAI_API_KEY)
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_instruction},  # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {e}"

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
