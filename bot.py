import os
import logging
import openai
import asyncio
import faiss
import pickle
import shutil
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import CommandStart
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∂–µ–Ω –ª–∏ –∫–ª—é—á
if not OPENAI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç OPENAI_API_KEY. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Railway.")

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á API OpenAI
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ó–∞–≥—Ä—É–∑–∫–∞ FAISS-–∏–Ω–¥–µ–∫—Å–∞
INDEX_FOLDER = "faiss_index"
INDEX_ZIP = "faiss_index.zip"

if os.path.exists(INDEX_ZIP):
    shutil.unpack_archive(INDEX_ZIP, INDEX_FOLDER)
    vector_store = FAISS.load_local(INDEX_FOLDER, OpenAIEmbeddings())
else:
    vector_store = None

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(CommandStart())
async def start_handler(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –Ω–µ–π—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç ü§ñ. –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã, –∏ —è –ø–æ–º–æ–≥—É!")

# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def process_message(message: Message):
    user_input = message.text
    response = ask_ai(user_input)
    await message.answer(response)

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ FAISS –∏ OpenAI

def ask_ai(query: str) -> str:
    global vector_store
    if vector_store:
        docs = vector_store.similarity_search(query, k=2)
        context = "\n".join([doc.page_content for doc in docs])
        query = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {query}"
    
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    try:
        response = client.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[{"role": "user", "content": query}]
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI: {e}"

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
